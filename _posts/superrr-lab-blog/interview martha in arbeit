---
layout: post
type: lab
author: Feven Keleta
title: Foxglove Founder Martha Dark Talks Tech for Good: From Challenging Big Tech Workplace Abuse to Making Tech Accessible for All 
description: An Interview 
<img src="/assets/img/blog/Martha Dark Quote 2.png" alt="Illustration of Martha Dark" width="500" height="600">

<p><em><a href="https://www.foxglove.org.uk/who-we-are/people/martha-dark-director/">Martha Dark</a> Martha Dark is the co-founder and director of Foxglove, a London-based non-profit organization and advocacy group dedicated to improving the working conditions of content moderators. In addition to investigating, litigating, and campaigning on technology and social justice matters, Foxglove strives to challenge the harms caused by Big Tech and make technology fair and accessible to everyone. Today, we have the pleasure of talking to Martha about these crucial issues.</em></p>


<p><b>SUPERRR:</b> Dear Martha, how would you describe Foxglove to someone who has never heard of it?</p>

<p><b>Martha:</b> Foxglove is an organisation that exists to make the use of technology fair. I think technology increasingly is used by governments and private companies to exercise power, without proper safeguards and accountability, and Foxglove aims to counterbalance that power and take some of that power back into the hands of citizens and workers. And we bring legal cases against the UK government when they use algorithms in a way that's unfair or discriminatory. And we bring legal cases against big tech companies when they abuse their power or their workers.</p>

<p><b>SUPERRR:</b> The work Foxglove does is really important because many people are not aware of their rights in digital spaces, especially marginalised communities, who are at higher risk. So what exactly inspired you to found Foxglove? Was there a particular experience that prompted it, or was it more of an amalgamation of things that happened?</p>

<p><b>Martha:</b> Yeah, so I founded Foxglove with two friends of mine. Two of us worked for an organisation called “Reprieve”, which dealt with issues relating to the “War on Terror”. During this time, we witnessed numerous instances where technology was used, such as in drone strikes, resulting in the deaths of civilians and other harmful consequences. It was alarming to think that such life or death decisions could be made with the click of a button. We spent a lot of time researching the space to avoid replicating anything anyone else was doing, and we saw an opportunity for litigation. That's how we started Foxglove, which was initially a working title, but the name stuck. Foxglove is also the name of an English wildflower, which is similar to technology in that it can be both a cure and a poison.</p>

<p><b>SUPERRR:</b> Speaking of wildflowers, I wanted to ask you about the foxglove flower, because I think it's a pretty apt analogy for the work that you do. You said it's like technology in that it can be both a harm and a cure. When we take this analogy and apply it to practice, how has Foxglove stepped in to make sure that the outcome is ultimately for the greater good, and not just for a select few? How do you ensure that technology is used for good?</p>

<p><b>Martha:</b> Foxglove has brought and won multiple cases against the UK Government for using problematic, discriminatory or otherwise unfair algorithms. And every time we have brought a case challenging one of these systems, we haven't got to court because the system has been rolled back before we've got to court. So it's clear that the system is so inherently unfair or discriminatory that actually, as soon as it's challenged, they stop using it.
A lot of the work is using the law to ensure that technology is used in a fair way as it relates to the public sector. One of the interesting things about the public sector work is that algorithmic decision making is a relatively new way to make decisions, and it is not something that the public has ever voted on. It isn't transparent or open, and it isn't something that is consulted upon. The public has never been asked if this is the way that decisions should be made.</p>

<p><b>SUPERRR:</b> On a related note -  can you describe a specific project or case that Foxglove has been involved in or currently works on? How does it align with the organisation‘s mission to make tech fair and accessible for everyone?</p>

<p><b>Martha:</b> An example is our very first case, where we challenged the Home Office in the UK for using an algorithm that discriminated on the basis of nationality. If you held some nationalities, which were secret, you were automatically put in the red queue. It meant that your application was treated materially differently than if you were put in the green queue. If you held some nationalities, you just did no't get a visa, which is obviously awful and a breach of the 'Equality Act.'
An ongoing case that we're working on at the moment is challenging the Department of Work and Pensions, which looks after benefits in the UK, for using an algorithm that we think unfairly flags disabled people for benefit fraud investigations. The impact of that is that many disabled people across the UK, and we're working with a really great group in Manchester called the Greater Manchester Coalition for Disabled People, are being flagged for benefit fraud investigations much more regularly than people who are not disabled.
So, we use the law, and alongside the legal cases, we bring campaigns that engage the public. Whether that's campaigns engaging members of the public to donate to make the case possible, or to sign a petition or write to their MP about an issue. Or it might be engaging MPs directly in Parliament as well.</p>

<p><b>SUPERRR:</b> Can you provide some background on former content moderator Daniel Motaung's legal case against Meta/Facebook and Sama in Kenya? In the German context, many people are unaware of the awful working conditions of outsourced content moderators in the Global South.</p>

<p><b>Martha:</b> So, Daniel is a former content moderator who lives in South Africa and was a content moderator in Nairobi, Kenya. As you say, the working conditions in Samba and Kenya are pretty awful. The pay was less than $2 an hour, and there was no meaningful psychological care to ensure that moderators, who were looking at all sorts of awful content, day in and day out -  including beheadings and child pornography. As a result, Daniel and his colleagues tried to form a union. Consequently, Daniel and his colleauges were fired by Facebook and Sama in 2019. Now he's bringing a case against Facebook and Sama, seeking changes to the way Facebook treats content moderators because Facebook outsources content moderators all over the world. We don't know exactly how many moderators there are because Facebook refuses to say, but we think there are about 15,000, including many in Germany who are attending the summit that Foxglove, SUPERRR Lab, Aspiration and ver.di are putting on.
Daniel's case is fighting for fairer conditions for moderators and the right to form a union. Recently, Facebook was trying to argue that there was no jurisdiction to sue them in Kenya, despite Nairobi being the content moderation hub for all of South and East Africa, which is about 500 million people, and millions of users and advertising revenue from that region. They were saying that because they did not have a registered office there, they could not be sued. The judge ruled that Daniel was correct and that Daniel did have jurisdiction to sue in Kenya. Facebook has now appealed that decision, so we will now go through the appeals process. Daniel's case is essential not just from a workers’ rights perspective but also because there's much debate about how we keep the internet safe, how we moderate content, and what content should stay up and what should go down. The reality is that there's no way that the internet can be a safe place until the work conditions of content moderators have improved. We can't expect a safe internet when those protecting it are working in such horrible conditions.
We will have between 40 and 50 moderators gathering in Berlin from across Germany on March 9th and 10th. Unlike in Kenya, Germany has a strong labour union, and many moderators are already members of ver.di. Some are even forming workers' councils. The movement to organise and fight back against Big Tech is growing across the world, as we have seen with Amazon workers in the US and with my upcoming visit to Coventry to join the picket line of striking Amazon workers in the UK. There's a real moment of worker power building against Big Tech, who have built their wealth and power by crushing workers' rights for decades. It's an interesting time.</p>

<p><b>SUPERRR:</b> Yes, indeed. When you were telling me about Daniel Motaung's case, I was struck by its historical significance – I’m sure, people will talk about this case in the future, if not now!</p>

<p><b>Martha:</b> Yeah! It's the first case, to my knowledge across the world of a content moderator bringing a case against Facebook. So I think it's a really interesting and important landmark case!</p>

<p><b>SUPERRR:</b> It's amazing to see how Foxglove is making an impact on the fight against Big Tech.Who are the key players and networks that empower and uplift your work, and what are the partnerships you rely on to drive meaningful change?
</p>

<p><b>Martha:</b> Yeah, so we're really pleased to be partnering with everybody that we're partnering with on the summit. So, ver.di is an amazing union. And it's lovely to be working with them. The idea for the summit came from the Digital Futures Gathering that SUPERRR Lab hosted back in October, an Aspiration are going to be amazing facilitators and help make a really good conversation happen. So we're excited about that. But all Foxglove's work is taken in partnership. We always work with either in the case of algorithmic systems we work with either impacted individuals or groups, and in the cases against Big Tech.</p>

<p><b>SUPERRR:</b> Last, but not least, please fill in the gaps: "I know we are winning, when...."</p>

<p><b>Martha:</b> "......Big Tech is broken up, it's too big to exist is a threat to our societies, our democracies and our workplaces."</p>


<p><b>SUPERRR:</b> I agree! Thank you for sharing your insights and experiences with us, Martha. It was truly inspiring to hear about the work that Foxglove is doing!</p>
