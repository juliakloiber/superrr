---
title: "Superrr Expertenbeitrag – Enquete-Kommission Künstliche Intelligenz"
header_type: lab
order: 1
layout: project
img: ""
external_link: ""
link: '/project/enquete'
description: "Die Enquete-Kommission hat zum Thema Frauen und KI getagt und wir waren eingeladen, das Thema aus einer feminitischen Perspektive heraus zu betrachten."



---
<h1>Superrr Expertenbeitrag – Enquete-Kommission Künstliche Intelligenz</h1>
<p>Mehr Informationen und das Video zur Sitzung findet ihr <a href="https://www.bundestag.de/ausschuesse/weitere_gremien/enquete_ki#url=L2Rva3VtZW50ZS90ZXh0YXJjaGl2LzIwMjAva3cxMC1wYS1lbnF1ZXRlLWtpLTY4NDA1OA==&mod=mod569768">hier</a>.
</p>
<p>Es folgt die Textfassung des Expertenbeitrags </p>

<h1>Expertenanhörung: KI und Frauen/Fachkräftegewinnung</h1>
<p>2. März 2020 | Paul Löbe Haus </p>

<p>Laut einem aktuellen<a href="http://www3.weforum.org/docs/WEF_GGGR_2020.pdf">Bericht des Weltwirtschaftsforums</a> sind hierzulande nur 16% aller KI-Fachkräfte weiblich. In der KI-Forschung ist die Kluft noch gravierender, auf ArXiv sind im Bereich von KI <a href="https://www.nesta.org.uk/report/gender-diversity-ai/">lediglich 13,83% der Autoren Frauen</a>.
Anhand dieser Zahlen wird schnell klar: Bei diesem Thema lohnt es sich, genauer hinzusehen. Ich freue mich, dass wir dies heute tun. Ich werde in den nächsten 10 Minuten Daten, ADM-Systeme und die gesellschaftlichen Auswirkungen von Automatisierung beleuchten.
Ich werde dabei nicht nur über Frauen reden, sondern auch über Macht und darüber, wer sie hat und wer nicht. In einer Welt, in der Daten Macht sind, und diese Macht ungleichmäßig ausgeübt wird, kann eine feministische Perspektive helfen zu verstehen, wie Ungleichgewicht zustande kommt und wie eine positive Veränderung bewirkt werden kann.
Ich werde auch nicht nur über künstliche Intelligenz sprechen. Selbst wenn Machine Learning -basierte Systeme eine bestimmte Art von Problemen mit sich bringen, so sind sie am Ende auch nur ein Implementationsdetail von Automatisierung.
</p>
<p>Der Gender-Data-Gap<p>
 
<p>Expertensysteme oder prozedural programmierte Algorithmen entstehen dadurch, dass ein (statistisch gesehen männlicher) Entwickler an seinem Schreibtisch sitzt, und eine Anzahl von Regeln definiert. Zusammen mit einem Input-Datensatz wird daraus ein Output. Das macht am Ende das Regelsystem vergleichsweise überschaubar und nachvollziehbar.
ML-basierte Systeme hingegen, starten nicht mit einem solchen Regelwerk. Sie generieren aus Input und Output Regeln. Diese basieren auf statistischen Verteilungen und sind für Menschen oft nur schwer verständlich. Aus einer Liste von 40 Millionen Gleitkommazahlen zu erkennen, ob es sich um das Foto einer Katze handelt oder nicht, ist für Menschen unmöglich. Ebenso sind die Regeln oft nur so gut, wie der Datensatz, mit dem das System gefüttert wurde.
In ihrem Buch <a href="https://www.randomhouse.de/Paperback/Unsichtbare-Frauen/Caroline-Criado-Perez/btb/e561586.rhd">"Unsichtbare Frauen"</a> schreibt Caroline Criado Perez über den Gender-Data-Gap und darüber, dass in einer von Daten beherrschten Welt die Hälfte der Bevölkerung ignoriert wird. Sie spricht von Spracherkennungssystemen die Frauen um 70% schlechter verstehen als Männer, Crashtestdummies, die der männlichen Physis folgen und medizinischer Forschung, die auf Männer hin ausgerichtet ist. Verzerrungen in den Daten, ob explizit annotiert oder implizit durch Proxies, können so zu einem Feedback-Loop führen, der bestehende Ungleichheiten noch verstärkt.

Das bedeutet natürlich nicht, dass menschliche Entscheidungsträger vorurteilsfrei sind. Im Gegensatz zum Menschen sind ADM-Systeme aber konsistent. Ihr Einsatz ist eine gute Chance, unsere Denksysteme und Prozesse zu reflektieren.
● Marginalisierte Gruppen & Frauen sind in Datensätzen oft unterrepräsentiert.
● Selbst wenn man z. B. Geschlecht filtert, wird der Algorithmus Proxies identifizieren.
● Stattdessen: Transparenz welche Daten erhoben werden, um es zu ermöglichen, bessere Systeme zu entwickeln.
● Aber: es kann auch Vorteile für bestimmte Gruppen haben, wenn sie nicht erfasst werden.

<p>Intersektionalität</p>

<p>Im Zusammenhang mit Diskriminierung ist es wichtig anzumerken, dass diese mehrdimensional stattfinden kann. Eine Frau kann beispielsweise nicht nur Unterdrückung wegen ihres Geschlechts erfahren, sondern auch wegen ihres Alters, ihrer Religion, ihrer Herkunft und vielem mehr. Es gibt mehrere, sich überschneidende Machtsysteme.
Natürlich sind nicht immer nur Frauen betroffen. Es gibt zahlreiche Ungleichverteilungen in unserer Gesellschaft, die Diskriminierung vermuten lassen. Ein Beispiel sind Ostdeutsche bei der Wahl zum Vorstandsvorsitzenden oder Menschen mit Migrationshintergrund bei der Wohnungssuche.
Ein Ansatz, um Inklusion und Geschlechtergerechtigkeit zu fördern, ist es diese in das Zentrum politischer Entscheidungsfindung zu rücken. Ein Beispiel dafür ist <a href="https://www.government.se/government-policy/feminist-foreign-policy/">“Feminist Foreign Policy”</a> in Schweden. Erst wenn unterschiedlichste Bereiche auf Geschlechter-Ungerechtigkeiten hin untersucht werden, besteht eine Möglichkeit diese zu erkennen und zu beheben.
Wissenschaftler*innen und Entwickler*innen können geschlechtsspezifische Vorurteile besser vermeiden, wenn sie sich derer bewusst sind. Wissen rund um Gendernormen und Gender-Identitäten, muss daher in den entsprechenden technischen Fächern unterrichtet werden.
Handlungsvorschläge:
● Geschlechtergerechtigkeit ins Zentrum politischer Entscheidungsprozesse stellen.
● Teams divers besetzen, damit unterschiedliche Perspektiven in die Entwicklung von
ADM-Systemen einfließen.
● Wissen rund um Genderidentitäten und -normen an Informatik-Studiengängen unterrichten.
</p>

<p>Aber was, wenn die Systeme bereits ausgerollt sind?</p>
<p>Zivilgesellschaft muss mit am Tisch sitzen</p>

<p>Die polnische NGO <a href="https://en.panoptykon.org/">Fundacja Panoptykon</a> hat über Recherchen und Analysen demonstriert, dass ein vom Ministerium für Arbeit und Soziales eingesetzter Algorithmus für Arbeitslosenförderung, in seiner Ausführung nicht verfassungskonform war. Mit dem Ergebnis, dass der Algorithmus eingestellt wurde. Auf die Details einzugehen würde den Rahmen sprengen. Was ich damit aufzeigen will ist, dass zivilgesellschaftliche Organisationen eine wichtige Rolle als Watchdog für Bürgerrechte im digitalen Raum spielen. Aber auch, wenn es darum geht, gesellschaftliche Herausforderungen zu identifizieren und Ideen für den Einsatz von KI zu entwerfen, die einen gesellschaftlichen Nutzen bringen, ist Zivilgesellschaft unabdingbar.
Wenn es schon vergleichsweise kleinen Organisationen wie Fundacja Panoptykon5 gelingt, solche Schwächen in ADM-Systemen ans Tageslicht und diese sogar zu Fall zu bringen, was könnten dann erst spezialisierte, zivilgesellschaftliche Organisationen mit genügend Ressourcen erreichen?
 
In einem aktuellen Bericht der <a href="https://www.stiftung-nv.de/de/publikation/towards-european-ai-society-ecosystem">Stiftung Neue Verantwortung</a>, geht es genau um dieses Thema. Nämlich darum, wie ein europäisches Ökosystem mit Fokus auf KI und Gesellschaft gefördert werden kann. Ein zentraler Faktor sind dabei zivilgesellschaftliche Organisationen.</p>

<p>Handlungsvorschläge:

● Spezielle Förderprogramme für zivilgesellschaftliche Organisationen mit Fokus auf Gesellschaft und KI & Automatisierung.
○ Europaweite Vernetzung fördern
○ Zusammenarbeit mit Forschungseinrichtungen ermöglichen </p>

<p>Interdisziplinäre Forschung</p>

<p>Der europäische Diskurs über künstliche Intelligenz wird oft durch eine Reihe von hochkarätigen US-amerikanischen Beispielen zu den Risiken und dem Missbrauch von KI dominiert. Diese Beispiele gelten nicht unbedingt auch für den europäischen regulatorischen und kulturellen Kontext. Es braucht mehr Forschung über die gesellschaftlichen Auswirkungen und Chancen neuer Technologien im europäischen Kontext, sowie wissenschaftliche Arbeit über Fachbereiche hinweg, wie wir es aus der Volkswirtschaftslehre, der Soziologie und der Neurologie kennen.</p>
<p>Handlungsvorschlag:
● Interdisziplinäre Forschung in der KI fördern z. B. über Förderprogramme.
</p>
 
<p>Automatisierung und Abstraktion</p>

<p>ML ermöglicht neue, vorher nicht umsetzbare Produkte, die oftmals auch einen Paradigmenwechsel mit sich bringen. Das führt zu neuen Abstraktionsebenen und Plattformen: Autos statt Pferden, selbstfahrende Autos statt Chauffeuren. Bei selbstfahrenden Autos haben wir das Abstraktionslevel beispielsweise schon erreicht: Wenn Sie sich heute vorstellen wollen, wie es ist, ein selbstfahrendes Auto zu haben, rufen Sie sich ein Uber und reden einfach nicht mit dem Fahrer.
Aber es gibt auch subtilere Effekte von Automatisierung. Zum Beispiel im Bereich der Sprachassistenzsysteme. Apples Siri hat zwar in den meisten Sprachen eine männliche Stimme im Angebot, die Voreinstellung in Deutschland und in vielen anderen Ländern, ist jedoch eine weibliche Stimme.
Amazons Alexa, zeigt sich von der Aufforderung, auf eine männliche Stimme umzuschalten, überfordert. Dafür kann man sich für ¢99 den Wetterbericht von Samuel L. Jackson vortragen lassen. Immerhin.
Was aber sagt das über unser Frauenbild aus, wenn unsere automatisierten Bediensteten die Rolle von Frauen annehmen?
Dieser Punkt mag auf den ersten Blick vielleicht trivial erscheinen, aber solche Interfaces haben direkte Auswirkungen auf unsere Wahrnehmung. Die <a href="https://unesdoc.unesco.org/ark:/48223/pf0000367416.page=7">UNESCO kommt in einem Bericht</a> zu dem Schluss, dass unterwürfige und teils inkompetente digitale Sprachassistenten Genderstereotype verstärken.
Es ist vergleichsweise simpel, hier die Hersteller in die Verantwortung zu rufen. Eine einfache Auswahlmöglichkeit der Stimme beim ersten Aufsetzen des Telefons bzw. des Smart Speakers gibt jedem Nutzer und jeder Nutzerin selbst die Möglichkeit, über das Geschlecht zu bestimmen.</p>
<p>Handlungsvorschläge:
● Hersteller anregen, eine Geschlechtsauswahl bei den Sprachassistenten anzubieten.
● Sprachmodelle entwickeln die nicht geschlechtsspezifisch sind.
Es gibt aber auch makroskopische Effekte, die von maschinellem Lernen begünstigt werden. Nämlich die Tatsache, dass Automatisierung unterschiedliche Berufsgruppen unterschiedlich stark betrifft.
Radiologie oder Reisebüro, Anwaltskanzlei oder Zahnarztpraxis. Ich will an dieser Stelle nicht spekulieren, welche Berufsgruppen stärker von Automatisierung bedroht sind, aber es gibt wenig Grund anzunehmen, dass es alle Arbeitnehmer und Arbeitnehmer*innen gleich stark betrifft. Welche Berufe wird es in 20 Jahren noch geben und wie kann sich Deutschland auf diesen Wandel vorbereiten?</p>

 
<p>Da viele Berufsfelder ein Ungleichgewicht in der Geschlechterverteilung aufweisen, wird sich auch Automatisierung ungleichmäßig auf Geschlechter auswirken. Was hat es für soziale Auswirkungen, wenn 500.000 männliche Kraftfahrer ihren Job verlieren, 500.000 weibliche Pflegekräfte aber nicht?
Hier lohnt es sich die Geschlechter-Perspektive in die Forschung miteinzubeziehen. Morgen launcht das <a href="https://www.denkfabrik-bmas.de/themen/kuenstliche-intelligenz/ki-observatorium">KI-Observatorium des Bundesministeriums für Arbeit und Soziales</a>. Die Vorankündigungen klingen vielversprechend. Ich hoffe, dass sich das Observatorium auch Fragestellungen wie der oben genannten widmen wird.</p>

<p>Handlungsvorschlag:</p>
<p>
● Die Auswirkungen von Automatisierung auf die Gesellschaft (u.a. in Hinblick auf Gender und Diversität) gezielt erforschen.
Mehr Diversität in der KI-Entwicklung und in Entscheidungspositionen
Zu Beginn dieser Präsentation habe ich über Macht gesprochen. Ein wichtiger Machtfaktor ist die Frage danach, wer über den Einsatz bestimmter Technologien bestimmt und wer sie gestaltet.
Es gibt eine wachsende Distanz zwischen denjenigen, die diese Systeme entwerfen und einsetzen, und denjenigen, die von diesen Systemen betroffen sind. Wie aktuelle Zahlen belegen, sind zum Beispiel Frauen kaum im Raum, wenn KI entwickelt wird. Von Zahlen über Minderheiten und andere Gruppen (die teilweise gar nicht erhoben werden) ganz zu schweigen.
Mehr weibliche Fachkräfte auszubilden ist nur eine wichtige Maßnahme von vielen, die ergriffen werden muss, um Geschlechtergerechtigkeit Realität werden zu lassen. In diesem Zusammenhang ist es wichtig, eine Reihe weiterer Faktoren zu berücksichtigen:
● Es braucht nicht nur mehr Frauen, sondern grundsätzlich mehr Diversität und Vielfalt.
● Das Arbeitsklima in Tech-Unternehmen und an Universitäten spielt eine entscheidende
Rolle, ob Frauen und Minderheiten in ihren Jobs bleiben und sich dort entwickeln können.
Das wissen wir nicht erst seit den weltweiten Google-Walkouts.
● Auch die Führungsetagen müssen diverser und weiblicher werden. Es geht nicht nur
darum, die Entwickler*innen- Teams divers zu besetzen, sondern auch Bereiche, in denen
wegweisende Entscheidungen getroffen werden.
● Es muss grundsätzlich mehr Forschung zu soziotechnischen Systemen und deren
Auswirkungen geben. Chancen & Visionen</p>

<p>
Ich will diesen Vortrag mit einer Visionen schließen und der Frage nachgehen, wie uns neue Technologien einen Schritt weiter in Richtung einer inklusiven Gesellschaft bringen können.
Inklusion beginnt nicht selten mit Sprache und Verständigung. Gerade im Bereich Übersetzung, haben uns ML basierte Systeme einen großen Schritt weiter gebracht. Man stelle sich eine Zukunft vor, in der die Inhalte einer europäischen Mediathek in allen Sprachen, von Baskisch über Sorbisch bis hin zu Gebärdensprache verfügbar sind. Nicht mit gelben Untertiteln, sondern mit von KI-Systemen synthetisierten Audiospuren, in der Originalstimme des Schauspielers oder der Schauspielerin sowie mit passenden Lippenbewegungen.</p>
<p>Es sind solche Visionen, die wir für die Entwicklung neuer Technologien brauchen. Dabei gilt es Programme zu fördern, die die Entwicklung neuer Ideen und Ansätze ermöglichen. Laden Sie sich auch mehrere unterschiedliche Perspektiven in diese Kommission ein, wie beispielsweise Sozialunternehmer*innen, Künstler*innen oder Zivilgesellschaft.</p>
<p>Handlungsvorschläge:</p>
<p>
● Kreative Ideen & Visionen über speziell angepasste Programme fördern. Beispiele: der Prototype Fund und die Agentur für Sprunginnovationen.
● Sich viele unterschiedliche Perspektiven als Expert*innen in die Kommission einladen: Zivilgesellschaft, Startups, Künstler*innen, ...
Es folgt eine Zusammenfassung meiner Handlungsvorschläge: Zusammenfassung der Handlungsvorschläge
● Das Thema KI & Frauen weiter fassen und über Vielfalt, Inklusion und Geschlechtergerechtigkeit sprechen.
● Interdisziplinäre Forschung im Bereich KI Studiengänge wie Sozioinformatik ausbauen.
● Ein Ökosystem für KI und Gesellschaft aufbauen: Zivilgesellschaftliche Organisationen
fördern und ihnen einen Platz am Tisch geben. Z. B. über agile und innovative
Förderprogramme.
● Kurzfristige Maßnahme: Empfehlung zur Geschlechterauswahl bei Sprachassistenzsystemen. </p>

<p>Vielen Dank.</p>




