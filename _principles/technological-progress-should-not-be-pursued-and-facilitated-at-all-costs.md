---
title: "No to progress at any cost."
order: 6
layout: principle
img: "/assets/img/static/principles/1000x1000.png"
description: 'Some technologies are simply too harmful to be deployed in the first place. Red lines on harmful technological practices must be set and more research must be conducted on the potential harm of emerging technologies on communities at the margins. Processes for feedback, evaluation and veto must be established.'
---

## Sarah Chander:

»Currently, there exists no right to review and revoke technology. The dominance of Big Tech, alongside the increased equation of capitalist extraction with technological progress, has led to an overwhelming presumption among policymakers, industry, and even parts of civil society, that the societal impacts of technology are, at the very least, “neutral”, and that technology represents, by nature, progress to be pursued and facilitated at all costs.

Yet some technologies are simply too harmful to be deployed in the first place, and we should not assume a single trajectory for innovation and progress. As the work of Ruha Benjamin, Safiya Noble, Joy Buolamwini, Timnit Gebru, Deborah Raji and many others gains recognition, we are seeing a growing acknowledgement among [institutions](https://www.ohchr.org/EN/NewsEvents/Pages/DisplayNews.aspx?NewsID=27469&LangID=E) and [civil society](https://edri.org/our-work/civil-society-call-for-ai-red-lines-in-the-european-unions-artificial-intelligence-proposal/) that red lines must be set on harmful technological practices, especially those that [differentiate, target and experiment on communities at the margins](https://www.enar-eu.org/Data-racism-a-new-frontier) – racialised people, undocumented migrants, queer and trans communities, and people with disabilities.

We need to instil some democracy into our conceptions of emerging technologies in such a way that does not presume that technological innovation benefits all, but rather that capitalist developments require some to be subjected, experimented upon, extracted from and disadvantaged in order for others to gain from the process.

What we need is a recognition that technology for some uses (like the distribution and monitoring of policing and other carceral infrastructure, targeted and mass surveillance, and the enforcement of borders) will inherently harm us as disabled people, migrants, women*, queer, trans and racialised people.

Why? Because such technologies are already premised upon destructive infrastructures, systems and societies. They can’t help us when working for those structures. The only way out is resistance – for us to put the needs of the marginalised at the centre and to seize our right to review, revoke and refuse.«

<div class="principle-info-box" markdown="1">

### Who can inspire us with their work?

»Some of the most astounding work on the right to refuse harmful technological practices has been carried out by women of colour across the world who have developed myriad techniques for resistance. In addition to those already outlined above in the US context, Dr Seeta Peña Gangadharan has done crucial work on theorising the need to [decenter technology](https://www.tandfonline.com/doi/full/10.1080/1369118X.2019.1593484) and embed resistance within broader social justice work. She is implementing this with the [Justice, Equity and Technology Table](https://www.lse.ac.uk/justice-equity-technology). Nani Jansen Reventlow at the Digital Freedom Fund has mobilised resources to support communities and activists counter harmful technological practices, as well as advocating for the need to [decolonise the European digital rights field](https://digitalfreedomfund.org/decolonising/). And alongside Claire Fernandez, Laurence Meyer and Joel Hilde at DFF/EDRi, Dr Seda Gürses has consistently drawn attention to how technological dominance manifests not just through singular technological applications but through computational infrastructures which form the basis of multiple social, political and economic disadvantages for our societies, work she has [explored further](https://edri.org/wp-content/uploads/2021/09/EDRi_Beyond-Debiasing-Report_Online.pdf) with Agathe Balayn.« — Sarah Chander

</div>







